{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "from scipy import io\n",
    "import numpy as np\n",
    "import scipy\n",
    "from PIL import Image, ImageOps\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv())\n",
    "project_dir = Path(os.getenv(\"project_dir\")).resolve()\n",
    "output_filepath = project_dir / \"data\" / \"processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive = np.load(output_filepath / \"vegfru_data.npz\")\n",
    "x_train = archive[\"x_train\"]\n",
    "y_train = archive[\"y_train\"]\n",
    "x_test = archive[\"x_test\"]\n",
    "y_test = archive[\"y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexd\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:72: UserWarning: h5py is running against HDF5 1.10.2 when it was built against 1.10.3, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "num_classes=292\n",
    "target_size = 96\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def preprocess_image(im):\n",
    "    return cv2.resize(im, dsize=(target_size, target_size), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "def load_data_generator(x, y, batch_size=64):\n",
    "    num_samples = x.shape[0]\n",
    "    while 1:\n",
    "        try:\n",
    "            x, y = shuffle(x, y)\n",
    "            for i in range(0, num_samples, batch_size):\n",
    "                x_data = np.array([preprocess_image(x[i]) for i in range(i, i+batch_size)])\n",
    "                y_data = y[i:i + batch_size]\n",
    "            \n",
    "                # convert to numpy array since this what keras required\n",
    "                yield x_data, y_data\n",
    "        except Exception as err:\n",
    "            print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://hackernoon.com/tf-serving-keras-mobilenetv2-632b8d92983c\n",
    "from keras.applications.mobilenetv2 import MobileNetV2\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    input_tensor = Input(shape=(target_size, target_size, 3))\n",
    "    base_model = MobileNetV2(\n",
    "        include_top=False,\n",
    "        weights=None,\n",
    "        input_tensor=input_tensor,\n",
    "        input_shape=(target_size, target_size, 3),\n",
    "        pooling='avg')\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True  \n",
    "        \n",
    "    op = Dense(256, activation='relu')(base_model.output)\n",
    "    op = Dropout(.25)(op)\n",
    "    \n",
    "    output_tensor = Dense(num_classes, activation='softmax')(op)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=output_tensor)\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "model = build_model()\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "(16, 96, 96, 3)\n",
      "(16, 96, 96, 3)\n",
      "(16, 96, 96, 3)\n",
      "(16, 96, 96, 3)\n",
      "(16, 96, 96, 3)\n",
      "(16, 96, 96, 3)\n",
      "(16, 96, 96, 3)\n",
      "(16, 96, 96, 3)\n",
      "(16, 96, 96, 3)\n",
      "(16, 96, 96, 3)\n",
      "(16, 96, 96, 3)\n",
      "(16, 96, 96, 3)\n",
      " 1/20 [>.............................] - ETA: 12:28 - loss: 5.9368 - categorical_accuracy: 0.0000e+00(16, 96, 96, 3)\n",
      " 2/20 [==>...........................] - ETA: 9:23 - loss: 5.8354 - categorical_accuracy: 0.0000e+00 (16, 96, 96, 3)\n",
      " 3/20 [===>..........................] - ETA: 8:27 - loss: 5.8730 - categorical_accuracy: 0.0000e+00(16, 96, 96, 3)\n",
      " 4/20 [=====>........................] - ETA: 7:52 - loss: 5.8588 - categorical_accuracy: 0.0000e+00(16, 96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "train_generator = load_data_generator(x_train, y_train, batch_size=batch_size)\n",
    "\n",
    "model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    steps_per_epoch=20, #x_train.shape[0] // 64\n",
    "    verbose=1,\n",
    "    epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
